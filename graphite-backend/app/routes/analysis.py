"""
æ•°æ®åˆ†æAPIè·¯ç”±
æä¾›æ•°æ®æŸ¥è¯¢ã€æ¸…æ´—å’Œå›å½’åˆ†æåŠŸèƒ½
"""

from flask import Blueprint, request, jsonify
from flask_jwt_extended import jwt_required, get_jwt_identity
from sqlalchemy import text
from app import db
from app.utils.decorators import role_required
from app.utils.data_cleaning import clean_analysis_data, generate_cleaning_report
import numpy as np
from scipy import stats
from app.models.analysis_config import AnalysisConfig
from datetime import datetime

# åˆ›å»ºè“å›¾ï¼ˆä¸è®¾ç½®url_prefixï¼Œåœ¨__init__.pyä¸­ç»Ÿä¸€è®¾ç½®ï¼‰
analysis_bp = Blueprint('analysis', __name__)

# å­—æ®µå…ƒæ•°æ®ï¼ˆä¸­æ–‡åç§°å’Œå•ä½ï¼‰
# âœ… 2025-12-31 ä¿®æ­£ï¼šæ ¹æ®æ•°æ®åº“å®é™…å­—æ®µå’Œç”¨æˆ·åé¦ˆä¿®æ­£æ‰€æœ‰å­—æ®µæ˜ å°„
FIELD_METADATA = {
    # ç¢³åŒ–å‚æ•°
    'carbon_max_temp': {'label': 'ç¢³åŒ–æœ€é«˜æ¸©åº¦', 'unit': 'â„ƒ'},
    'carbon_total_time': {'label': 'ç¢³åŒ–æ€»æ—¶é•¿', 'unit': 'min'},
    'carbon_yield_rate': {'label': 'ç¢³åŒ–æˆç¢³ç‡', 'unit': '%'},  # âœ… ä¿®æ­£ï¼šä»"ç¢³åŒ–æ”¶ç‡"æ”¹ä¸º"ç¢³åŒ–æˆç¢³ç‡"
    
    # çŸ³å¢¨åŒ–å‚æ•°
    'graphite_max_temp': {'label': 'çŸ³å¢¨åŒ–æœ€é«˜æ¸©åº¦', 'unit': 'â„ƒ'},
    'graphite_total_time': {'label': 'çŸ³å¢¨åŒ–æ€»æ—¶é•¿', 'unit': 'min'},
    'graphite_yield_rate': {'label': 'çŸ³å¢¨åŒ–æ”¶ç‡', 'unit': '%'},
    'inner_foaming_thickness': {'label': 'å·å†…å‘æ³¡åšåº¦', 'unit': 'Î¼m'},
    'outer_foaming_thickness': {'label': 'å·å¤–å‘æ³¡åšåº¦', 'unit': 'Î¼m'},
    'shrinkage_ratio': {'label': 'æ”¶ç¼©æ¯”', 'unit': '%'},  # âœ… ä¿®æ­£ï¼šä»æˆå“å‚æ•°ç§»è‡³çŸ³å¢¨åŒ–å‚æ•°
    
    # æˆå“å‚æ•°
    'thermal_conductivity': {'label': 'å¯¼çƒ­ç³»æ•°', 'unit': 'W/mÂ·K'},
    'avg_density': {'label': 'å¹³å‡å¯†åº¦', 'unit': 'g/cmÂ³'},
    'avg_thickness': {'label': 'å¹³å‡åšåº¦', 'unit': 'Î¼m'},
    'specific_heat': {'label': 'æ¯”çƒ­', 'unit': 'J/gÂ·K'},  # âœ… æ–°å¢ï¼šè¡¥å……ç¼ºå¤±å­—æ®µ
    'cohesion': {'label': 'å†…èšåŠ›', 'unit': 'gf'},  # âœ… ä¿®æ­£ï¼šä» MPa æ”¹ä¸º gf
    'peel_strength': {'label': 'å‰¥ç¦»åŠ›', 'unit': 'gf'},  # âœ… ä¿®æ­£ï¼šä»"å‰¥ç¦»å¼ºåº¦ (N/cm)"æ”¹ä¸º"å‰¥ç¦»åŠ› (gf)"
    'bond_strength': {'label': 'ç»“åˆåŠ›', 'unit': 'gf'},  # âœ… æ–°å¢ï¼šè¡¥å……ç¼ºå¤±å­—æ®µ
    
    # PIè†œå‚æ•°
    'pi_film_thickness': {'label': 'PIè†œåšåº¦', 'unit': 'Î¼m'},
    
    # åŸºæœ¬å‚æ•°
    'graphite_model': {'label': 'çŸ³å¢¨å‹å·', 'unit': ''}
}


@analysis_bp.route('/data', methods=['GET'])
@jwt_required()
@role_required(['admin', 'engineer'])
def get_analysis_data():
    """
    è·å–åˆ†ææ•°æ®ï¼ˆä½¿ç”¨ v_experiment_full è§†å›¾ï¼‰
    """
    # ===== è°ƒè¯•æ‰“å°å¼€å§‹ =====
    print("=" * 60)
    print("ğŸ“Š [DEBUG] get_analysis_data å‡½æ•°è¢«è°ƒç”¨")
    print(f"ğŸ“Š [DEBUG] è¯·æ±‚å‚æ•°: {dict(request.args)}")
    print("=" * 60)
    
    try:
        # 1. è·å–å¿…å¡«å‚æ•°
        x_field = request.args.get('x_field')
        y_field = request.args.get('y_field')
        
        print(f"ğŸ“Š [DEBUG] x_field={x_field}, y_field={y_field}")
        
        if not x_field or not y_field:
            print("âŒ [DEBUG] ç¼ºå°‘å¿…å¡«å­—æ®µ")
            return jsonify({
                'error': 'Missing required fields',
                'message': 'è¯·é€‰æ‹©Xè½´å’ŒYè½´å­—æ®µ'
            }), 400
        
        # 2. éªŒè¯å­—æ®µæ˜¯å¦å­˜åœ¨ï¼ˆç™½åå•æ£€æŸ¥ï¼Œé˜²æ­¢SQLæ³¨å…¥ï¼‰
        if x_field not in FIELD_METADATA or y_field not in FIELD_METADATA:
            print(f"âŒ [DEBUG] å­—æ®µä¸å­˜åœ¨: x_field={x_field}, y_field={y_field}")
            return jsonify({
                'error': 'Invalid field',
                'message': 'é€‰æ‹©çš„å­—æ®µä¸å­˜åœ¨'
            }), 400
        
        print("âœ… [DEBUG] å­—æ®µéªŒè¯é€šè¿‡")
        
        # 3. æ„å»ºåŸºç¡€ SQL
        query = f"""
            SELECT 
                experiment_code,
                {x_field} as x_value,
                {y_field} as y_value
            FROM v_experiment_full
            WHERE {x_field} IS NOT NULL 
              AND {y_field} IS NOT NULL
              AND status IN ('submitted', 'completed')
        """
        
        print(f"ğŸ“Š [DEBUG] åŸºç¡€SQLæ„å»ºå®Œæˆ")
        
        # 4. åŠ¨æ€æ·»åŠ ç­›é€‰æ¡ä»¶
        filters = []
        params = {}

        # æ—¥æœŸç­›é€‰
        date_start = request.args.get('date_start')
        print(f"ğŸ“Š [DEBUG] date_start åŸå§‹å€¼: {repr(date_start)}")
        if date_start and date_start.strip():
            filters.append("experiment_date >= :date_start")
            params['date_start'] = date_start
            print(f"âœ… [DEBUG] æ·»åŠ  date_start ç­›é€‰: {date_start}")

        date_end = request.args.get('date_end')
        print(f"ğŸ“Š [DEBUG] date_end åŸå§‹å€¼: {repr(date_end)}")
        if date_end and date_end.strip():
            filters.append("experiment_date <= :date_end")
            params['date_end'] = date_end
            print(f"âœ… [DEBUG] æ·»åŠ  date_end ç­›é€‰: {date_end}")

        # PI è†œå‹å·ç­›é€‰
        pi_film_model = request.args.get('pi_film_model')
        print(f"ğŸ“Š [DEBUG] pi_film_model åŸå§‹å€¼: {repr(pi_film_model)}")
        if pi_film_model:
            models = [m.strip() for m in pi_film_model.split(',') if m.strip()]
            print(f"ğŸ“Š [DEBUG] è§£æåçš„ models: {models}")
            if models:
                placeholders = ','.join([f':model_{i}' for i in range(len(models))])
                filters.append(f"pi_film_model IN ({placeholders})")
                for i, model in enumerate(models):
                    params[f'model_{i}'] = model
                print(f"âœ… [DEBUG] æ·»åŠ  pi_film_model ç­›é€‰: {models}")

        # âœ… çŸ³å¢¨å‹å·ç­›é€‰
        graphite_model = request.args.get('graphite_model')
        print(f"ğŸ“Š [DEBUG] graphite_model åŸå§‹å€¼: {repr(graphite_model)}")
        if graphite_model:
            models = [m.strip() for m in graphite_model.split(',') if m.strip()]
            print(f"ğŸ“Š [DEBUG] è§£æåçš„ graphite models: {models}")
            if models:
                placeholders = ','.join([f':graphite_model_{i}' for i in range(len(models))])
                filters.append(f"graphite_model IN ({placeholders})")
                for i, model in enumerate(models):
                    params[f'graphite_model_{i}'] = model
                print(f"âœ… [DEBUG] æ·»åŠ  graphite_model ç­›é€‰: {models}")

        # âœ… çƒ§ç»“åœ°ç‚¹ç­›é€‰ - æ–°å¢è¿™éƒ¨åˆ†ï¼
        sintering_location = request.args.get('sintering_location')
        print(f"ğŸ“Š [DEBUG] sintering_location åŸå§‹å€¼: {repr(sintering_location)}")
        if sintering_location:
            locations = [loc.strip() for loc in sintering_location.split(',') if loc.strip()]
            print(f"ğŸ“Š [DEBUG] è§£æåçš„ locations: {locations}")
            if locations:
                placeholders = ','.join([f':location_{i}' for i in range(len(locations))])
                filters.append(f"sintering_location IN ({placeholders})")
                for i, loc in enumerate(locations):
                    params[f'location_{i}'] = loc
                print(f"âœ… [DEBUG] æ·»åŠ  sintering_location ç­›é€‰: {locations}")

        # æ‹¼æ¥ SQL
        if filters:
            query += " AND " + " AND ".join(filters)
            print(f"âœ… [DEBUG] æ·»åŠ äº† {len(filters)} ä¸ªç­›é€‰æ¡ä»¶")
        else:
            print("â„¹ï¸ [DEBUG] æ— é¢å¤–ç­›é€‰æ¡ä»¶")

        # ===== æ‰“å°æœ€ç»ˆSQL =====
        print("=" * 60)
        print("ğŸ“Š [DEBUG] æœ€ç»ˆSQLæŸ¥è¯¢:")
        print(query)
        print(f"ğŸ“Š [DEBUG] å‚æ•°å­—å…¸: {params}")
        print("=" * 60)

        # 5. æ‰§è¡ŒæŸ¥è¯¢
        try:
            result = db.session.execute(text(query), params)
            raw_data = [dict(row._mapping) for row in result]
            print(f"âœ… [DEBUG] SQLæ‰§è¡ŒæˆåŠŸï¼Œè¿”å› {len(raw_data)} æ¡æ•°æ®")
            
            if len(raw_data) > 0:
                print(f"ğŸ“Š [DEBUG] ç¬¬ä¸€æ¡æ•°æ®ç¤ºä¾‹: {raw_data[0]}")
        except Exception as sql_error:
            print("=" * 60)
            print(f"âŒ [DEBUG] SQLæ‰§è¡Œå¤±è´¥")
            print(f"   é”™è¯¯ç±»å‹: {type(sql_error).__name__}")
            print(f"   é”™è¯¯ä¿¡æ¯: {str(sql_error)}")
            print("=" * 60)
            import traceback
            traceback.print_exc()
            raise
        
        # 6. æ•°æ®æ¸…æ´—
        exclude_zero = request.args.get('exclude_zero', 'true').lower() == 'true'
        enable_outlier = request.args.get('enable_outlier_detection', 'true').lower() == 'true'
        outlier_method = request.args.get('outlier_method', 'iqr')
        
        print(f"ğŸ“Š [DEBUG] æ•°æ®æ¸…æ´—å‚æ•°: exclude_zero={exclude_zero}, enable_outlier={enable_outlier}, method={outlier_method}")
        
        cleaned_result = clean_analysis_data(
            raw_data,
            exclude_zero=exclude_zero,
            enable_outlier_detection=enable_outlier,
            outlier_method=outlier_method
        )
        
        print(f"âœ… [DEBUG] æ•°æ®æ¸…æ´—å®Œæˆï¼Œæœ‰æ•ˆæ•°æ®: {len(cleaned_result['data'])} æ¡")
        
        # 7. ç”ŸæˆæŠ¥å‘Š
        cleaning_report = generate_cleaning_report(cleaned_result['statistics'])
        
        print("âœ… [DEBUG] åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ")
        print("=" * 60)
        
        return jsonify({
            'data': cleaned_result['data'],
            'metadata': {
                'x_field': x_field,
                'x_label': FIELD_METADATA[x_field]['label'],
                'x_unit': FIELD_METADATA[x_field]['unit'],
                'y_field': y_field,
                'y_label': FIELD_METADATA[y_field]['label'],
                'y_unit': FIELD_METADATA[y_field]['unit']
            },
            'statistics': cleaned_result['statistics'],
            'cleaning_report': cleaning_report
        }), 200
    
    except Exception as e:
        import traceback
        print("=" * 60)
        print("âŒ [DEBUG] æ•°æ®åˆ†ææŸ¥è¯¢å¤±è´¥")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        print("   å®Œæ•´å †æ ˆ:")
        traceback.print_exc()
        print("=" * 60)
        
        return jsonify({
            'error': 'Data retrieval failed',
            'message': str(e),
            'error_type': type(e).__name__
        }), 500


@analysis_bp.route('/linear-regression', methods=['POST'])
@jwt_required()
@role_required(['admin', 'engineer'])
def linear_regression():
    """
    æ‰§è¡Œçº¿æ€§å›å½’åˆ†æ
    
    Request Body:
        {
            "data": [
                {"x": 2400, "y": 1050},
                {"x": 2600, "y": 1280},
                ...
            ]
        }
    
    Returns:
        {
            "equation": "y = 0.52x - 195.6",
            "slope": 0.52,
            "intercept": -195.6,
            "r_squared": 0.956,
            "p_value": 0.0001,
            "n": 25,
            "predictions": [...],
            "quality_assessment": {...}
        }
    """
    try:
        # 1. è·å–æ•°æ®
        request_data = request.get_json()
        data_points = request_data.get('data', [])
        
        if not data_points:
            return jsonify({
                'error': 'No data provided',
                'message': 'æ²¡æœ‰æä¾›æ•°æ®ç‚¹'
            }), 400
        
        # 2. æå–Xå’ŒYå€¼ï¼ˆåªä½¿ç”¨æœ‰æ•ˆæ•°æ®ï¼‰
        valid_points = [p for p in data_points if isinstance(p, dict) and 'x' in p and 'y' in p]
        
        if len(valid_points) < 2:
            return jsonify({
                'error': 'Insufficient data',
                'message': 'æ•°æ®ç‚¹ä¸è¶³ï¼Œè‡³å°‘éœ€è¦2ä¸ªç‚¹è¿›è¡Œå›å½’åˆ†æ',
                'data_count': len(valid_points)
            }), 400
        
        x_values = np.array([p['x'] for p in valid_points], dtype=float)
        y_values = np.array([p['y'] for p in valid_points], dtype=float)
        
        # 3. è¾¹ç¼˜æƒ…å†µæ£€æŸ¥
        if np.all(x_values == x_values[0]):
            return jsonify({
                'error': 'No variance in X',
                'message': 'Xè½´æ•°æ®æ— å˜åŒ–ï¼Œæ— æ³•è®¡ç®—å›å½’æ–¹ç¨‹',
                'x_value': float(x_values[0])
            }), 400
        
        if np.all(y_values == y_values[0]):
            return jsonify({
                'error': 'No variance in Y',
                'message': 'Yè½´æ•°æ®æ— å˜åŒ–ï¼Œæ— æ³•è®¡ç®—å›å½’æ–¹ç¨‹',
                'y_value': float(y_values[0])
            }), 400
        
        # 4. æ‰§è¡Œçº¿æ€§å›å½’
        try:
            slope, intercept, r_value, p_value, std_err = stats.linregress(x_values, y_values)
        except Exception as e:
            return jsonify({
                'error': 'Regression calculation failed',
                'message': f'å›å½’è®¡ç®—å¤±è´¥: {str(e)}'
            }), 500
        
        # 5. è®¡ç®—RÂ²
        r_squared = r_value ** 2
        
        # 6. ç”Ÿæˆå›å½’æ–¹ç¨‹å­—ç¬¦ä¸²
        if intercept >= 0:
            equation = f"y = {slope:.4f}x + {intercept:.4f}"
        else:
            equation = f"y = {slope:.4f}x - {abs(intercept):.4f}"
        
        # 7. ç”Ÿæˆé¢„æµ‹ç‚¹ï¼ˆç”¨äºç»˜åˆ¶å›å½’çº¿ï¼‰
        x_min, x_max = np.min(x_values), np.max(x_values)
        x_range = x_max - x_min
        x_pred = np.linspace(x_min - 0.1 * x_range, x_max + 0.1 * x_range, 50)
        y_pred = slope * x_pred + intercept
        
        predictions = [
            {'x': float(x), 'y': float(y)}
            for x, y in zip(x_pred, y_pred)
        ]
        
        # 8. è´¨é‡è¯„ä¼°
        quality_assessment = {
            'fit_quality': _assess_fit_quality(r_squared),
            'significance': _assess_significance(p_value)
        }
        
        # 9. è¿”å›ç»“æœ
        return jsonify({
            'equation': equation,
            'slope': float(slope),
            'intercept': float(intercept),
            'r_squared': float(r_squared),
            'p_value': float(p_value),
            'std_err': float(std_err),
            'n': len(valid_points),
            'predictions': predictions,
            'quality_assessment': quality_assessment
        }), 200
    
    except Exception as e:
        return jsonify({
            'error': 'Analysis failed',
            'message': str(e)
        }), 500


def _assess_fit_quality(r_squared: float) -> str:
    """è¯„ä¼°æ‹Ÿåˆè´¨é‡"""
    if r_squared >= 0.9:
        return 'excellent'
    elif r_squared >= 0.75:
        return 'good'
    elif r_squared >= 0.5:
        return 'fair'
    else:
        return 'poor'


def _assess_significance(p_value: float) -> str:
    """è¯„ä¼°æ˜¾è‘—æ€§"""
    if p_value < 0.001:
        return 'highly_significant'
    elif p_value < 0.05:
        return 'moderately_significant'
    else:
        return 'not_significant'


@analysis_bp.route('/field-options', methods=['GET'])
@jwt_required()
def get_field_options():
    """
    è·å–å¯ç”¨äºåˆ†æçš„å­—æ®µåˆ—è¡¨
    
    Returns:
        {
            'fields': [
                {
                    'value': 'graphite_max_temp',
                    'label': 'çŸ³å¢¨åŒ–æœ€é«˜æ¸©åº¦',
                    'unit': 'â„ƒ',
                    'category': 'process'
                },
                ...
            ]
        }
    """
    fields = []
    
    # åˆ†ç±»å®šä¹‰
    categories = {
        'carbonization': 'ç¢³åŒ–å‚æ•°',
        'graphitization': 'çŸ³å¢¨åŒ–å‚æ•°',
        'product': 'æˆå“å‚æ•°',
        'pi_film': 'PIè†œå‚æ•°',
        'rolling': 'å‹å»¶å‚æ•°',
        'basic': 'åŸºæœ¬å‚æ•°'
    }
    
    # âœ… å­—æ®µåˆ†ç±»ä¿®æ­£ï¼ˆ2025-12-31ï¼‰
    field_categories = {
        # ç¢³åŒ–å‚æ•°
        'carbon_max_temp': 'carbonization',
        'carbon_total_time': 'carbonization',
        'carbon_yield_rate': 'carbonization',
        
        # çŸ³å¢¨åŒ–å‚æ•°
        'graphite_max_temp': 'graphitization',
        'graphite_total_time': 'graphitization',
        'graphite_yield_rate': 'graphitization',
        'inner_foaming_thickness': 'graphitization',
        'outer_foaming_thickness': 'graphitization',
        'shrinkage_ratio': 'graphitization',  # âœ… ä¿®æ­£ï¼šä»productç§»è‡³graphitization
        
        # æˆå“å‚æ•°
        'thermal_conductivity': 'product',
        'avg_density': 'product',
        'avg_thickness': 'product',
        'specific_heat': 'product',  # âœ… æ–°å¢
        'cohesion': 'product',
        'peel_strength': 'product',
        'bond_strength': 'product',  # âœ… æ–°å¢
        
        # PIè†œå‚æ•°
        'pi_film_thickness': 'pi_film',
        
        # åŸºæœ¬å‚æ•°
        'graphite_model': 'basic'
    }
    
    for field_name, metadata in FIELD_METADATA.items():
        fields.append({
            'value': field_name,
            'label': metadata['label'],
            'unit': metadata['unit'],
            'category': field_categories.get(field_name, 'other'),
            'category_label': categories.get(field_categories.get(field_name, 'other'), 'å…¶ä»–')
        })
    
    return jsonify({'fields': fields}), 200

# ========================================
# é…ç½®ç®¡ç† API
# ========================================

@analysis_bp.route('/configs', methods=['POST'])
@jwt_required()
@role_required(['admin', 'engineer'])
def save_config():
    """
    ä¿å­˜åˆ†æé…ç½®
    
    Request Body:
        {
            "name": "çŸ³å¢¨åŒ–æ¸©åº¦ vs æ¯”çƒ­",
            "description": "ç ”ç©¶çŸ³å¢¨åŒ–æ¸©åº¦å¯¹æ¯”çƒ­çš„å½±å“ï¼ˆå¯é€‰ï¼‰",
            "config": {
                "x_axis": {
                    "field": "graphite_max_temp", 
                    "label": "çŸ³å¢¨åŒ–æœ€é«˜æ¸©åº¦", 
                    "unit": "â„ƒ"
                },
                "y_axis": {
                    "field": "specific_heat", 
                    "label": "æ¯”çƒ­", 
                    "unit": "J/gÂ·K"
                },
                "filters": {
                    "date_start": "2024-01-01",
                    "date_end": "2024-12-31",
                    "pi_film_models": ["GH-100"],
                    "graphite_models": ["SGF-010"],
                    "sintering_locations": ["DG"]
                },
                "cleaning_options": {
                    "exclude_zero": true,
                    "enable_outlier_detection": true,
                    "outlier_method": "iqr"
                }
            }
        }
    
    Returns:
        {
            "id": 1,
            "name": "...",
            "message": "é…ç½®ä¿å­˜æˆåŠŸ"
        }
    """
    try:
        # 1. è·å–å½“å‰ç”¨æˆ·
        current_user_id = get_jwt_identity()
        
        # 2. è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        name = data.get('name')
        description = data.get('description', '')
        config_data = data.get('config')
        
        # 3. éªŒè¯å¿…å¡«å­—æ®µ
        if not name or not config_data:
            return jsonify({
                'error': 'Missing required fields',
                'message': 'é…ç½®åç§°å’Œé…ç½®æ•°æ®ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # 4. éªŒè¯é…ç½®æ•°æ®ç»“æ„
        required_keys = ['x_axis', 'y_axis']
        if not all(key in config_data for key in required_keys):
            return jsonify({
                'error': 'Invalid config structure',
                'message': 'é…ç½®æ•°æ®å¿…é¡»åŒ…å« x_axis å’Œ y_axis'
            }), 400
        
        # 5. æ£€æŸ¥é…ç½®åç§°æ˜¯å¦é‡å¤ï¼ˆåŒä¸€ç”¨æˆ·ï¼‰
        existing = AnalysisConfig.query.filter_by(
            name=name,
            created_by=current_user_id
        ).first()
        
        if existing:
            return jsonify({
                'error': 'Config name exists',
                'message': f'é…ç½®åç§°"{name}"å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–åç§°'
            }), 400
        
        # 6. åˆ›å»ºé…ç½®è®°å½•
        # âœ… JSONå­—æ®µä¼šè‡ªåŠ¨ä¿å­˜æ‰€æœ‰æ–°å­—æ®µï¼š
        #    - filters.graphite_models
        #    - y_axis.field = 'specific_heat' æˆ– 'bond_strength' ç­‰
        config = AnalysisConfig(
            name=name,
            description=description,
            config_data=config_data,
            created_by=current_user_id
        )
        
        db.session.add(config)
        db.session.commit()
        
        print(f"âœ… é…ç½®ä¿å­˜æˆåŠŸ: ID={config.id}, name={config.name}, user={current_user_id}")
        
        return jsonify({
            'id': config.id,
            'name': config.name,
            'message': 'é…ç½®ä¿å­˜æˆåŠŸ'
        }), 201
    
    except Exception as e:
        db.session.rollback()
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': 'Save failed',
            'message': str(e)
        }), 500


@analysis_bp.route('/configs', methods=['GET'])
@jwt_required()
@role_required(['admin', 'engineer'])
def get_configs():
    """
    è·å–ç”¨æˆ·çš„åˆ†æé…ç½®åˆ—è¡¨
    
    Query Parameters:
        - page: é¡µç ï¼ˆé»˜è®¤1ï¼‰
        - per_page: æ¯é¡µæ•°é‡ï¼ˆé»˜è®¤20ï¼‰
    
    Returns:
        {
            "configs": [
                {
                    "id": 1,
                    "name": "...",
                    "description": "...",
                    "config": {
                        "x_axis": {...},
                        "y_axis": {...},
                        "filters": {
                            "graphite_models": ["SGF-010"],
                            ...
                        },
                        "cleaning_options": {...}
                    },
                    "view_count": 10,
                    "last_run_at": "2024-12-30T10:30:00",
                    "created_at": "2024-12-29T08:00:00"
                }
            ],
            "total": 5,
            "page": 1,
            "per_page": 20
        }
    """
    try:
        # 1. è·å–å½“å‰ç”¨æˆ·
        current_user_id = get_jwt_identity()
        
        # 2. è·å–åˆ†é¡µå‚æ•°
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        
        # 3. æŸ¥è¯¢ç”¨æˆ·çš„é…ç½®ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´å€’åºï¼‰
        query = AnalysisConfig.query.filter_by(created_by=current_user_id)
        
        # 4. åˆ†é¡µ
        pagination = query.order_by(AnalysisConfig.created_at.desc()).paginate(
            page=page,
            per_page=per_page,
            error_out=False
        )
        
        # 5. è½¬æ¢ä¸ºå­—å…¸
        configs = [config.to_dict() for config in pagination.items]
        
        print(f"âœ… æŸ¥è¯¢é…ç½®åˆ—è¡¨æˆåŠŸ: user={current_user_id}, count={len(configs)}")
        
        return jsonify({
            'configs': configs,
            'total': pagination.total,
            'page': page,
            'per_page': per_page,
            'pages': pagination.pages
        }), 200
    
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢é…ç½®åˆ—è¡¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': 'Query failed',
            'message': str(e)
        }), 500


@analysis_bp.route('/configs/<int:config_id>', methods=['GET'])
@jwt_required()
@role_required(['admin', 'engineer'])
def get_config(config_id):
    """
    è·å–å•ä¸ªé…ç½®è¯¦æƒ…
    
    åŒæ—¶æ›´æ–°æŸ¥çœ‹æ¬¡æ•°å’Œæœ€åè¿è¡Œæ—¶é—´
    
    Returns:
        {
            "id": 1,
            "name": "...",
            "description": "...",
            "config": {
                "x_axis": {...},
                "y_axis": {"field": "specific_heat", ...},
                "filters": {"graphite_models": ["SGF-010"], ...}
            },
            "view_count": 11,
            "last_run_at": "2024-12-30T10:30:00"
        }
    """
    try:
        # 1. è·å–å½“å‰ç”¨æˆ·
        current_user_id = get_jwt_identity()
        
        # 2. æŸ¥è¯¢é…ç½®
        config = AnalysisConfig.query.filter_by(
            id=config_id,
            created_by=current_user_id
        ).first()
        
        if not config:
            return jsonify({
                'error': 'Config not found',
                'message': 'é…ç½®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®'
            }), 404
        
        # 3. æ›´æ–°æŸ¥çœ‹æ¬¡æ•°å’Œæœ€åè¿è¡Œæ—¶é—´
        config.view_count += 1
        config.last_run_at = datetime.utcnow()
        db.session.commit()
        
        print(f"âœ… æŸ¥è¯¢é…ç½®æˆåŠŸ: ID={config_id}, view_count={config.view_count}")
        
        return jsonify(config.to_dict()), 200
    
    except Exception as e:
        db.session.rollback()
        print(f"âŒ æŸ¥è¯¢é…ç½®å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': 'Query failed',
            'message': str(e)
        }), 500


@analysis_bp.route('/configs/<int:config_id>', methods=['DELETE'])
@jwt_required()
@role_required(['admin', 'engineer'])
def delete_config(config_id):
    """
    åˆ é™¤åˆ†æé…ç½®
    
    Returns:
        {
            "message": "é…ç½®åˆ é™¤æˆåŠŸ"
        }
    """
    try:
        # 1. è·å–å½“å‰ç”¨æˆ·
        current_user_id = get_jwt_identity()
        
        # 2. æŸ¥è¯¢é…ç½®
        config = AnalysisConfig.query.filter_by(
            id=config_id,
            created_by=current_user_id
        ).first()
        
        if not config:
            return jsonify({
                'error': 'Config not found',
                'message': 'é…ç½®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®'
            }), 404
        
        # 3. åˆ é™¤é…ç½®
        config_name = config.name
        db.session.delete(config)
        db.session.commit()
        
        print(f"âœ… é…ç½®åˆ é™¤æˆåŠŸ: ID={config_id}, name={config_name}")
        
        return jsonify({
            'message': 'é…ç½®åˆ é™¤æˆåŠŸ'
        }), 200
    
    except Exception as e:
        db.session.rollback()
        print(f"âŒ åˆ é™¤é…ç½®å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': 'Delete failed',
            'message': str(e)
        }), 500


@analysis_bp.route('/configs/<int:config_id>', methods=['PUT'])
@jwt_required()
@role_required(['admin', 'engineer'])
def update_config(config_id):
    """
    æ›´æ–°åˆ†æé…ç½®
    
    Request Body:
        {
            "name": "æ–°çš„é…ç½®åç§°ï¼ˆå¯é€‰ï¼‰",
            "description": "æ–°çš„æè¿°ï¼ˆå¯é€‰ï¼‰",
            "config": {
                "x_axis": {...},
                "y_axis": {...},
                "filters": {
                    "graphite_models": ["SGF-015"],
                    ...
                },
                "cleaning_options": {...}
            }
        }
    
    Returns:
        {
            "id": 1,
            "name": "...",
            "message": "é…ç½®æ›´æ–°æˆåŠŸ"
        }
    """
    try:
        # 1. è·å–å½“å‰ç”¨æˆ·
        current_user_id = get_jwt_identity()
        
        # 2. æŸ¥è¯¢é…ç½®
        config = AnalysisConfig.query.filter_by(
            id=config_id,
            created_by=current_user_id
        ).first()
        
        if not config:
            return jsonify({
                'error': 'Config not found',
                'message': 'é…ç½®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®'
            }), 404
        
        # 3. è·å–æ›´æ–°æ•°æ®
        data = request.get_json()
        
        # 4. æ›´æ–°å­—æ®µ
        if 'name' in data:
            # æ£€æŸ¥æ–°åç§°æ˜¯å¦é‡å¤
            new_name = data['name']
            existing = AnalysisConfig.query.filter_by(
                name=new_name,
                created_by=current_user_id
            ).filter(AnalysisConfig.id != config_id).first()
            
            if existing:
                return jsonify({
                    'error': 'Config name exists',
                    'message': f'é…ç½®åç§°"{new_name}"å·²å­˜åœ¨'
                }), 400
            
            config.name = new_name
        
        if 'description' in data:
            config.description = data['description']
        
        if 'config' in data:
            # âœ… JSONå­—æ®µä¼šè‡ªåŠ¨ä¿å­˜æ‰€æœ‰æ›´æ–°çš„å­—æ®µ
            config.config_data = data['config']
        
        # 5. ä¿å­˜æ›´æ–°
        db.session.commit()
        
        print(f"âœ… é…ç½®æ›´æ–°æˆåŠŸ: ID={config_id}, name={config.name}")
        
        return jsonify({
            'id': config.id,
            'name': config.name,
            'message': 'é…ç½®æ›´æ–°æˆåŠŸ'
        }), 200
    
    except Exception as e:
        db.session.rollback()
        print(f"âŒ æ›´æ–°é…ç½®å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': 'Update failed',
            'message': str(e)
        }), 500